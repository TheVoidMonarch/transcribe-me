{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhil3dHQQUYS8j9NW1FOX+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheVoidMonarch/transcribe-me/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBmAicv_uOOR"
      },
      "outputs": [],
      "source": [
        "# üéôÔ∏è Audio Transcription with Whisper\n",
        "\n",
        "This notebook uses OpenAI's Whisper model to transcribe audio files to SRT format.\n",
        "\n",
        "## üîß Features\n",
        "- Automatic language detection\n",
        "- GPU acceleration (when available)\n",
        "- Multiple audio format support\n",
        "- Progress tracking\n",
        "\n",
        "## üìù Instructions\n",
        "1. Click the \"Copy to Drive\" button at the top\n",
        "2. Return to your Drive and open the notebook there\n",
        "3. Let the automation handle the rest!\n",
        "\n",
        "## ‚ö†Ô∏è Note\n",
        "This notebook is designed to work with the automated transcription system.\n",
        "Please don't modify the cells unless you know what you're doing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q openai-whisper==20231117 torch tqdm\n",
        "\n",
        "# Install ffmpeg if needed\n",
        "!which ffmpeg > /dev/null || apt install -y ffmpeg > /dev/null\n",
        "\n",
        "print(\"‚úÖ Dependencies installed successfully!\")"
      ],
      "metadata": {
        "id": "C12xgGtMu_B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Check CUDA\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Set device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load model\n",
        "print(\"\\nüìö Loading Whisper model...\")\n",
        "model = whisper.load_model(\"base\", device=DEVICE)\n",
        "print(\"‚úÖ Model loaded successfully!\")"
      ],
      "metadata": {
        "id": "7lINZkZuu_Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_timestamp(seconds: float) -> str:\n",
        "    \"\"\"Convert seconds to SRT timestamp format.\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = seconds % 60\n",
        "    msecs = int((secs % 1) * 1000)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{int(secs):02d},{msecs:03d}\"\n",
        "\n",
        "def save_as_srt(segments: list, output_file: str) -> None:\n",
        "    \"\"\"Save transcription segments as SRT file.\"\"\"\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for i, seg in enumerate(segments, start=1):\n",
        "            # Write segment number\n",
        "            f.write(f\"{i}\\n\")\n",
        "\n",
        "            # Write timestamps\n",
        "            start = format_timestamp(seg['start'])\n",
        "            end = format_timestamp(seg['end'])\n",
        "            f.write(f\"{start} --> {end}\\n\")\n",
        "\n",
        "            # Write text\n",
        "            f.write(f\"{seg['text'].strip()}\\n\\n\")\n",
        "\n",
        "def display_progress(text: str, color: str = 'blue') -> None:\n",
        "    \"\"\"Display progress message with color.\"\"\"\n",
        "    display(HTML(f\"<p style='color: {color}'>{text}</p>\"))"
      ],
      "metadata": {
        "id": "r2dFY6JgvToB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(audio_path: str) -> str:\n",
        "    \"\"\"Transcribe audio file and save as SRT.\"\"\"\n",
        "    try:\n",
        "        # Transcribe\n",
        "        display_progress(\"üéØ Transcribing audio...\")\n",
        "        result = model.transcribe(\n",
        "            audio_path,\n",
        "            verbose=True,\n",
        "            language=None,  # Auto-detect language\n",
        "            task=\"transcribe\",\n",
        "            fp16=torch.cuda.is_available()  # Use FP16 if GPU available\n",
        "        )\n",
        "\n",
        "        # Save as SRT\n",
        "        output_file = str(Path(audio_path).with_suffix('')) + \"_transcribed.srt\"\n",
        "        display_progress(\"üíæ Saving transcription...\")\n",
        "        save_as_srt(result[\"segments\"], output_file)\n",
        "\n",
        "        # Show completion message\n",
        "        display_progress(f\"‚úÖ Transcription saved to: {output_file}\", 'green')\n",
        "        if result.get(\"language\"):\n",
        "            display_progress(f\"üåç Detected language: {result['language']}\", 'green')\n",
        "\n",
        "        return output_file\n",
        "\n",
        "    except Exception as e:\n",
        "        display_progress(f\"‚ùå Error during transcription: {str(e)}\", 'red')\n",
        "        raise\n",
        "\n",
        "# Handle file upload and transcription\n",
        "from google.colab import files\n",
        "\n",
        "display_progress(\"üì§ Please upload an audio file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    display_progress(f\"\\nüéµ Processing: {filename}\")\n",
        "    output_file = transcribe_audio(filename)\n",
        "    display_progress(\"\\nüì• Downloading transcription...\")\n",
        "    files.download(output_file)"
      ],
      "metadata": {
        "id": "hgh9qyYLvTVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HmJknurHu_Zz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}